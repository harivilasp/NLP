{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stopword removal:  ['My', 'fellow', 'citizens', ':', 'I', 'stand', 'here', ...]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "@author: jacobjohn\n",
    "\n",
    "\"\"\"\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import tweepy\n",
    "\n",
    "##Using Obama's inaugural speech\n",
    "Obama = inaugural.words(fileids = '2009-Obama.txt')\n",
    "\n",
    "##stopword removal\n",
    "stop_words = set(stopwords.words('english')) \n",
    "filtered_sentence = [w for w in Obama if not w in stop_words]\n",
    "print(\"After stopword removal: \", Obama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries:  133737\n",
      "CMU word list:  ('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "CMU word list:  ('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "CMU word list:  ('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "CMU word list:  ('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "CMU word list:  ('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "CMU word list:  ('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "CMU word list:  ('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "CMU word list:  ('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "CMU word list:  ('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "CMU word list:  ('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "CMU word list:  ('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "CMU word list:  (\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "CMU word list:  ('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "CMU word list:  (\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "CMU word list:  ('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n",
      "CMU word list:  ('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D'])\n",
      "CMU word list:  ('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D'])\n",
      "CMU word list:  (\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D', 'Z'])\n",
      "CMU word list:  (\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D', 'Z'])\n",
      "CMU word list:  ('belgrave', ['B', 'EH1', 'L', 'G', 'R', 'EY2', 'V'])\n",
      "CMU word list:  ('beli', ['B', 'EH1', 'L', 'IY0'])\n",
      "CMU word list:  ('belich', ['B', 'EH1', 'L', 'IH0', 'K'])\n",
      "CMU word list:  ('belie', ['B', 'IH0', 'L', 'AY1'])\n",
      "CMU word list:  ('belied', ['B', 'IH0', 'L', 'AY1', 'D'])\n",
      "CMU word list:  ('belief', ['B', 'IH0', 'L', 'IY1', 'F'])\n"
     ]
    }
   ],
   "source": [
    "##CMU wordlist\n",
    "entries = nltk.corpus.cmudict.entries()\n",
    "print(\"Number of entries: \", len(entries))\n",
    "for entry in entries[10000:10025]:\n",
    "    print(\"CMU word list: \", entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Wordnet\n",
    "id = wn.synsets('motorcar') #you get an id for subsets\n",
    "id[0].lemma_names() #head words/lemmas in the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sentence', 'NN'), ('.', '.')]\n",
      "[('So', 'RB'), ('is', 'VBZ'), ('this', 'DT'), ('one', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "##NLTK pipeline\n",
    "\n",
    "texts = [\"\"\"This is a sentence. So is this one.\"\"\"] #paste text after the three quotes, organize into lines\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        print(tagged_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:  Andy Murray meets fellow injury sufferer James Duckworth at US Open https://t.co/Lds2CiW2V2\n",
      "Sentence tokenization:  ['Andy Murray meets fellow injury sufferer James Duckworth at US Open https://t.co/Lds2CiW2V2']\n",
      "Word tokenization:  ['Andy', 'Murray', 'meets', 'fellow', 'injury', 'sufferer', 'James', 'Duckworth', 'at', 'US', 'Open', 'https', ':', '//t.co/Lds2CiW2V2']\n",
      "Tweet tokenized:  ['Andy', 'Murray', 'meets', 'fellow', 'injury', 'sufferer', 'James', 'Duckworth', 'at', 'US', 'Open', 'https://t.co/Lds2CiW2V2']\n",
      "\n",
      "\n",
      "Tweet:  Srinagar hotel case: Major Leetul Gogoi found guilty, to face court martial https://t.co/ExJeEEMwIR https://t.co/2zcMUnuUfn\n",
      "Sentence tokenization:  ['Srinagar hotel case: Major Leetul Gogoi found guilty, to face court martial https://t.co/ExJeEEMwIR https://t.co/2zcMUnuUfn']\n",
      "Word tokenization:  ['Srinagar', 'hotel', 'case', ':', 'Major', 'Leetul', 'Gogoi', 'found', 'guilty', ',', 'to', 'face', 'court', 'martial', 'https', ':', '//t.co/ExJeEEMwIR', 'https', ':', '//t.co/2zcMUnuUfn']\n",
      "Tweet tokenized:  ['Srinagar', 'hotel', 'case', ':', 'Major', 'Leetul', 'Gogoi', 'found', 'guilty', ',', 'to', 'face', 'court', 'martial', 'https://t.co/ExJeEEMwIR', 'https://t.co/2zcMUnuUfn']\n",
      "\n",
      "\n",
      "Tweet:  Football transfer rumours: PSG to bid £100m for Spurs' Christian Eriksen? https://t.co/tudsFNtN4y\n",
      "Sentence tokenization:  [\"Football transfer rumours: PSG to bid £100m for Spurs' Christian Eriksen?\", 'https://t.co/tudsFNtN4y']\n",
      "Word tokenization:  ['Football', 'transfer', 'rumours', ':', 'PSG', 'to', 'bid', '£100m', 'for', 'Spurs', \"'\", 'Christian', 'Eriksen', '?', 'https', ':', '//t.co/tudsFNtN4y']\n",
      "Tweet tokenized:  ['Football', 'transfer', 'rumours', ':', 'PSG', 'to', 'bid', '£', '100m', 'for', 'Spurs', \"'\", 'Christian', 'Eriksen', '?', 'https://t.co/tudsFNtN4y']\n",
      "\n",
      "\n",
      "Tweet:  Maharashtra doctor couple funds heart surgeries of 2 kids on dead daughter's birthday https://t.co/LfuuzGK2Dw via… https://t.co/sy65ELJKOu\n",
      "Sentence tokenization:  [\"Maharashtra doctor couple funds heart surgeries of 2 kids on dead daughter's birthday https://t.co/LfuuzGK2Dw via… https://t.co/sy65ELJKOu\"]\n",
      "Word tokenization:  ['Maharashtra', 'doctor', 'couple', 'funds', 'heart', 'surgeries', 'of', '2', 'kids', 'on', 'dead', 'daughter', \"'s\", 'birthday', 'https', ':', '//t.co/LfuuzGK2Dw', 'via…', 'https', ':', '//t.co/sy65ELJKOu']\n",
      "Tweet tokenized:  ['Maharashtra', 'doctor', 'couple', 'funds', 'heart', 'surgeries', 'of', '2', 'kids', 'on', 'dead', \"daughter's\", 'birthday', 'https://t.co/LfuuzGK2Dw', 'via', '…', 'https://t.co/sy65ELJKOu']\n",
      "\n",
      "\n",
      "Tweet:  #JUSTIN | CBI sends a letter to Antigua government through Ministry of External Affairs; says, 'since the location… https://t.co/Cdy1VChkWv\n",
      "Sentence tokenization:  [\"#JUSTIN | CBI sends a letter to Antigua government through Ministry of External Affairs; says, 'since the location… https://t.co/Cdy1VChkWv\"]\n",
      "Word tokenization:  ['#', 'JUSTIN', '|', 'CBI', 'sends', 'a', 'letter', 'to', 'Antigua', 'government', 'through', 'Ministry', 'of', 'External', 'Affairs', ';', 'says', ',', \"'since\", 'the', 'location…', 'https', ':', '//t.co/Cdy1VChkWv']\n",
      "Tweet tokenized:  ['#JUSTIN', '|', 'CBI', 'sends', 'a', 'letter', 'to', 'Antigua', 'government', 'through', 'Ministry', 'of', 'External', 'Affairs', ';', 'says', ',', \"'\", 'since', 'the', 'location', '…', 'https://t.co/Cdy1VChkWv']\n",
      "\n",
      "\n",
      "Tweet:  Best Bodyweight Exercises for Targeting Specific Muscle Groups https://t.co/ebpYQN3OV1 https://t.co/9F5k7Qij2v\n",
      "Sentence tokenization:  ['Best Bodyweight Exercises for Targeting Specific Muscle Groups https://t.co/ebpYQN3OV1 https://t.co/9F5k7Qij2v']\n",
      "Word tokenization:  ['Best', 'Bodyweight', 'Exercises', 'for', 'Targeting', 'Specific', 'Muscle', 'Groups', 'https', ':', '//t.co/ebpYQN3OV1', 'https', ':', '//t.co/9F5k7Qij2v']\n",
      "Tweet tokenized:  ['Best', 'Bodyweight', 'Exercises', 'for', 'Targeting', 'Specific', 'Muscle', 'Groups', 'https://t.co/ebpYQN3OV1', 'https://t.co/9F5k7Qij2v']\n",
      "\n",
      "\n",
      "Tweet:  TOI Quick Edit | Hardik Patel returns with another quota agitation but India needs politicians who talk of growing… https://t.co/J5K6caTYyG\n",
      "Sentence tokenization:  ['TOI Quick Edit | Hardik Patel returns with another quota agitation but India needs politicians who talk of growing… https://t.co/J5K6caTYyG']\n",
      "Word tokenization:  ['TOI', 'Quick', 'Edit', '|', 'Hardik', 'Patel', 'returns', 'with', 'another', 'quota', 'agitation', 'but', 'India', 'needs', 'politicians', 'who', 'talk', 'of', 'growing…', 'https', ':', '//t.co/J5K6caTYyG']\n",
      "Tweet tokenized:  ['TOI', 'Quick', 'Edit', '|', 'Hardik', 'Patel', 'returns', 'with', 'another', 'quota', 'agitation', 'but', 'India', 'needs', 'politicians', 'who', 'talk', 'of', 'growing', '…', 'https://t.co/J5K6caTYyG']\n",
      "\n",
      "\n",
      "Tweet:  A Plane That Runs On Fuel Made by 500 Families, A First In India https://t.co/gtQ7Vob6zF #NDTVNewsBeeps https://t.co/6QudGLMe7b\n",
      "Sentence tokenization:  ['A Plane That Runs On Fuel Made by 500 Families, A First In India https://t.co/gtQ7Vob6zF #NDTVNewsBeeps https://t.co/6QudGLMe7b']\n",
      "Word tokenization:  ['A', 'Plane', 'That', 'Runs', 'On', 'Fuel', 'Made', 'by', '500', 'Families', ',', 'A', 'First', 'In', 'India', 'https', ':', '//t.co/gtQ7Vob6zF', '#', 'NDTVNewsBeeps', 'https', ':', '//t.co/6QudGLMe7b']\n",
      "Tweet tokenized:  ['A', 'Plane', 'That', 'Runs', 'On', 'Fuel', 'Made', 'by', '500', 'Families', ',', 'A', 'First', 'In', 'India', 'https://t.co/gtQ7Vob6zF', '#NDTVNewsBeeps', 'https://t.co/6QudGLMe7b']\n",
      "\n",
      "\n",
      "Tweet:  RT @Sports_NDTV: Asian Games: Aggressive display by India in Q4, Monika scores another one. India 3-0 Thailand in women's #Hockey Pool B ma…\n",
      "Sentence tokenization:  ['RT @Sports_NDTV: Asian Games: Aggressive display by India in Q4, Monika scores another one.', \"India 3-0 Thailand in women's #Hockey Pool B ma…\"]\n",
      "Word tokenization:  ['RT', '@', 'Sports_NDTV', ':', 'Asian', 'Games', ':', 'Aggressive', 'display', 'by', 'India', 'in', 'Q4', ',', 'Monika', 'scores', 'another', 'one', '.', 'India', '3-0', 'Thailand', 'in', 'women', \"'s\", '#', 'Hockey', 'Pool', 'B', 'ma…']\n",
      "Tweet tokenized:  ['RT', '@Sports_NDTV', ':', 'Asian', 'Games', ':', 'Aggressive', 'display', 'by', 'India', 'in', 'Q4', ',', 'Monika', 'scores', 'another', 'one', '.', 'India', '3-0', 'Thailand', 'in', \"women's\", '#Hockey', 'Pool', 'B', 'ma', '…']\n",
      "\n",
      "\n",
      "Tweet:  The 1,000km rainforest trek to protect an Amazon village from an uncontacted tribe https://t.co/w3eW9DkjiH\n",
      "Sentence tokenization:  ['The 1,000km rainforest trek to protect an Amazon village from an uncontacted tribe https://t.co/w3eW9DkjiH']\n",
      "Word tokenization:  ['The', '1,000km', 'rainforest', 'trek', 'to', 'protect', 'an', 'Amazon', 'village', 'from', 'an', 'uncontacted', 'tribe', 'https', ':', '//t.co/w3eW9DkjiH']\n",
      "Tweet tokenized:  ['The', '1,000', 'km', 'rainforest', 'trek', 'to', 'protect', 'an', 'Amazon', 'village', 'from', 'an', 'uncontacted', 'tribe', 'https://t.co/w3eW9DkjiH']\n",
      "\n",
      "\n",
      "Tweet:  RT @moviesndtv: After Roka, #PriyankaChopra, #NickJonas Pick Malibu For A Brunch Date https://t.co/fOLuZRrFMB https://t.co/OHpndcvPwK\n",
      "Sentence tokenization:  ['RT @moviesndtv: After Roka, #PriyankaChopra, #NickJonas Pick Malibu For A Brunch Date https://t.co/fOLuZRrFMB https://t.co/OHpndcvPwK']\n",
      "Word tokenization:  ['RT', '@', 'moviesndtv', ':', 'After', 'Roka', ',', '#', 'PriyankaChopra', ',', '#', 'NickJonas', 'Pick', 'Malibu', 'For', 'A', 'Brunch', 'Date', 'https', ':', '//t.co/fOLuZRrFMB', 'https', ':', '//t.co/OHpndcvPwK']\n",
      "Tweet tokenized:  ['RT', '@moviesndtv', ':', 'After', 'Roka', ',', '#PriyankaChopra', ',', '#NickJonas', 'Pick', 'Malibu', 'For', 'A', 'Brunch', 'Date', 'https://t.co/fOLuZRrFMB', 'https://t.co/OHpndcvPwK']\n",
      "\n",
      "\n",
      "Tweet:  Living in the company of the dead in Kerala village https://t.co/JR6NBTLE10 via @TOICitiesNews https://t.co/50dBWZIqLq\n",
      "Sentence tokenization:  ['Living in the company of the dead in Kerala village https://t.co/JR6NBTLE10 via @TOICitiesNews https://t.co/50dBWZIqLq']\n",
      "Word tokenization:  ['Living', 'in', 'the', 'company', 'of', 'the', 'dead', 'in', 'Kerala', 'village', 'https', ':', '//t.co/JR6NBTLE10', 'via', '@', 'TOICitiesNews', 'https', ':', '//t.co/50dBWZIqLq']\n",
      "Tweet tokenized:  ['Living', 'in', 'the', 'company', 'of', 'the', 'dead', 'in', 'Kerala', 'village', 'https://t.co/JR6NBTLE10', 'via', '@TOICitiesNews', 'https://t.co/50dBWZIqLq']\n",
      "\n",
      "\n",
      "Tweet:  Lead story now on https://t.co/Fbzw6mR9Q5: https://t.co/kTxZCPyO6e\n",
      "\n",
      "#NDTVLeadStory https://t.co/8fFj4GMXQl\n",
      "Sentence tokenization:  ['Lead story now on https://t.co/Fbzw6mR9Q5: https://t.co/kTxZCPyO6e\\n\\n#NDTVLeadStory https://t.co/8fFj4GMXQl']\n",
      "Word tokenization:  ['Lead', 'story', 'now', 'on', 'https', ':', '//t.co/Fbzw6mR9Q5', ':', 'https', ':', '//t.co/kTxZCPyO6e', '#', 'NDTVLeadStory', 'https', ':', '//t.co/8fFj4GMXQl']\n",
      "Tweet tokenized:  ['Lead', 'story', 'now', 'on', 'https://t.co/Fbzw6mR9Q5', ':', 'https://t.co/kTxZCPyO6e', '#NDTVLeadStory', 'https://t.co/8fFj4GMXQl']\n",
      "\n",
      "\n",
      "Tweet:  RT @Gadgets360: PUBG HP Omen Challenger Series Announced https://t.co/wIbcdFz9Iy #PUBG\n",
      "Sentence tokenization:  ['RT @Gadgets360: PUBG HP Omen Challenger Series Announced https://t.co/wIbcdFz9Iy #PUBG']\n",
      "Word tokenization:  ['RT', '@', 'Gadgets360', ':', 'PUBG', 'HP', 'Omen', 'Challenger', 'Series', 'Announced', 'https', ':', '//t.co/wIbcdFz9Iy', '#', 'PUBG']\n",
      "Tweet tokenized:  ['RT', '@Gadgets360', ':', 'PUBG', 'HP', 'Omen', 'Challenger', 'Series', 'Announced', 'https://t.co/wIbcdFz9Iy', '#PUBG']\n",
      "\n",
      "\n",
      "Tweet:  Another mass shooting unfolded in Florida, this time at a tournament for competitive players of the football video… https://t.co/WtdUfXhZgv\n",
      "Sentence tokenization:  ['Another mass shooting unfolded in Florida, this time at a tournament for competitive players of the football video… https://t.co/WtdUfXhZgv']\n",
      "Word tokenization:  ['Another', 'mass', 'shooting', 'unfolded', 'in', 'Florida', ',', 'this', 'time', 'at', 'a', 'tournament', 'for', 'competitive', 'players', 'of', 'the', 'football', 'video…', 'https', ':', '//t.co/WtdUfXhZgv']\n",
      "Tweet tokenized:  ['Another', 'mass', 'shooting', 'unfolded', 'in', 'Florida', ',', 'this', 'time', 'at', 'a', 'tournament', 'for', 'competitive', 'players', 'of', 'the', 'football', 'video', '…', 'https://t.co/WtdUfXhZgv']\n",
      "\n",
      "\n",
      "Tweet:  RT @toisports: .@Pvsindhu1 to fight for gold, @NSaina fetches bronze in Asian Games \n",
      "\n",
      "READ: https://t.co/yZqAWYHvQP\n",
      "\n",
      "#badminton #PVSindhu #…\n",
      "Sentence tokenization:  ['RT @toisports: .', '@Pvsindhu1 to fight for gold, @NSaina fetches bronze in Asian Games \\n\\nREAD: https://t.co/yZqAWYHvQP\\n\\n#badminton #PVSindhu #…']\n",
      "Word tokenization:  ['RT', '@', 'toisports', ':', '.', '@', 'Pvsindhu1', 'to', 'fight', 'for', 'gold', ',', '@', 'NSaina', 'fetches', 'bronze', 'in', 'Asian', 'Games', 'READ', ':', 'https', ':', '//t.co/yZqAWYHvQP', '#', 'badminton', '#', 'PVSindhu', '#', '…']\n",
      "Tweet tokenized:  ['RT', '@toisports', ':', '.', '@Pvsindhu1', 'to', 'fight', 'for', 'gold', ',', '@NSaina', 'fetches', 'bronze', 'in', 'Asian', 'Games', 'READ', ':', 'https://t.co/yZqAWYHvQP', '#badminton', '#PVSindhu', '#', '…']\n",
      "\n",
      "\n",
      "Tweet:  RT @Sports_NDTV: Asian Games: Rani Rampal scores another one early in Q4.  India 2-0 Thailand in women's #Hockey Pool B match\n",
      "\n",
      "#AsianGames…\n",
      "Sentence tokenization:  ['RT @Sports_NDTV: Asian Games: Rani Rampal scores another one early in Q4.', \"India 2-0 Thailand in women's #Hockey Pool B match\\n\\n#AsianGames…\"]\n",
      "Word tokenization:  ['RT', '@', 'Sports_NDTV', ':', 'Asian', 'Games', ':', 'Rani', 'Rampal', 'scores', 'another', 'one', 'early', 'in', 'Q4', '.', 'India', '2-0', 'Thailand', 'in', 'women', \"'s\", '#', 'Hockey', 'Pool', 'B', 'match', '#', 'AsianGames…']\n",
      "Tweet tokenized:  ['RT', '@Sports_NDTV', ':', 'Asian', 'Games', ':', 'Rani', 'Rampal', 'scores', 'another', 'one', 'early', 'in', 'Q4', '.', 'India', '2-0', 'Thailand', 'in', \"women's\", '#Hockey', 'Pool', 'B', 'match', '#AsianGames', '…']\n",
      "\n",
      "\n",
      "Tweet:  The 1,000km rainforest trek to protect an Amazon village from an uncontacted tribe | Dom Phillips and Gary Calton https://t.co/w3eW9D2HU7\n",
      "Sentence tokenization:  ['The 1,000km rainforest trek to protect an Amazon village from an uncontacted tribe | Dom Phillips and Gary Calton https://t.co/w3eW9D2HU7']\n",
      "Word tokenization:  ['The', '1,000km', 'rainforest', 'trek', 'to', 'protect', 'an', 'Amazon', 'village', 'from', 'an', 'uncontacted', 'tribe', '|', 'Dom', 'Phillips', 'and', 'Gary', 'Calton', 'https', ':', '//t.co/w3eW9D2HU7']\n",
      "Tweet tokenized:  ['The', '1,000', 'km', 'rainforest', 'trek', 'to', 'protect', 'an', 'Amazon', 'village', 'from', 'an', 'uncontacted', 'tribe', '|', 'Dom', 'Phillips', 'and', 'Gary', 'Calton', 'https://t.co/w3eW9D2HU7']\n",
      "\n",
      "\n",
      "Tweet:  Chelsea manager Maurizio Sarri surprised by Newcastle United’s tactics https://t.co/eiDz8KxtEk\n",
      "Sentence tokenization:  ['Chelsea manager Maurizio Sarri surprised by Newcastle United’s tactics https://t.co/eiDz8KxtEk']\n",
      "Word tokenization:  ['Chelsea', 'manager', 'Maurizio', 'Sarri', 'surprised', 'by', 'Newcastle', 'United', '’', 's', 'tactics', 'https', ':', '//t.co/eiDz8KxtEk']\n",
      "Tweet tokenized:  ['Chelsea', 'manager', 'Maurizio', 'Sarri', 'surprised', 'by', 'Newcastle', 'United', '’', 's', 'tactics', 'https://t.co/eiDz8KxtEk']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Implementing tokenization\n",
    "#Twitter aware tokenizer\n",
    "\n",
    "auth = tweepy.OAuthHandler(\"---\", \"---\")\n",
    "auth.set_access_token(\"---\", \"---\")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "tknzr = TweetTokenizer()\n",
    "for tweet in public_tweets:\n",
    "    print(\"Tweet: \",tweet.text)\n",
    "    sent = nltk.sent_tokenize(tweet.text)\n",
    "    print(\"Sentence tokenization: \", sent)\n",
    "    word = nltk.word_tokenize(tweet.text)\n",
    "    print(\"Word tokenization: \", word)\n",
    "    tweett = tknzr.tokenize(tweet.text)\n",
    "    print(\"Tweet tokenized: \",tweett)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
